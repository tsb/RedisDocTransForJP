Redisクラスターの仕様
===

**Redisクラスターの仕様**へようこそ。ここでは Redisクラスターに関するアルゴリズムやデザインを取り扱う。このドキュメントは完成版ではなく、実際の実装に沿って継続的に修正していく。


主要なプロパティとデザインについて
===

ゴール
---

デザイン面において、Redisクラスターは分散を実装したものであり、以下のようなゴールに基づいています。

* 高いパフォーマンスが 1000ノードまで線形にスケールする。プロキシはなく、非同期のレプリケーションを用い、値をマージすることもない。
* 書き込みの安全度: システムは（ベストエフォートで）多数派のマスターノードに接続しているクライアントからの書き込みリクエストを保持しようとします。たいてい、小さな幅ではありますが書き込みが失われることがあります。少数派のパーティションにクライアントが接続している場合、このウィンドウは大きくなります。
* 可用性: Redis クラスターは、多数派のマスターで疎通性があり、かつ疎通性が無い場合でも少なくとも 1つのスレーブが疎通性を保っていれば、パーティションを保持することができます。さらにいえば、*レプリカ移行*を用いて、スレーブがなくなったマスターは、複数のスレーブを持つマスターからレプリカを譲り受けることができます。

このドキュメントに書かれている機能は、Redis 3.0 以降で実装されています。


サブセットの実装
---

Redisクラスターでは単一のキーに関するコマンドについて、非分散型の Redis と同様に実装されています。Set系の結合や交差といった、複数のキーを扱う複雑なコマンドに関しては、同じノードにすべてのキーが存在する場合に限って動作するよう実装されています。

Redisクラスターは、まったく同じキーが毎回必ず同じノードに割り当てられるよう、**ハッシュタグ**と呼ばれるコンセプトで実装されています。しかし、手動でリシャーディングを行う場合は、単体キーの操作は可能であっても、複数キーの操作ができないタイミングがあるでしょう。

Redisクラスターは単独で動作する Redis とは異なり、複数のデータベースをサポートしません。データベースは常に 0 となり、これを変えるための `SELECT`コマンドは利用できません。


プロトコルにおけるクライアントとサーバーの役割
---

Redisクラスターのノードはデータを保管するとともに、ノード間でのキーの割り当てに関するマッピング情報やクラスターの情報を持ちます。クラスターノードは他のノードを自動的に追尾することができ、動作に問題があるノードを検知し、何らかの問題が発生したときにはスレーブをマスターに昇格させることができます。

TCPバスやバイナリープロトコルを用いてすべてのノードが繋がっている点について、これを **Redisクラスターバス**と呼びます。すべてのノードは、他のすべてのノードとクラスターバスを用いて接続されています。新しいノードの検知、他のすべてのノードが正しく動作していることを pingパケットで確認する、特定の条件を通知させるためのクラスターメッセージを送信する、そういった目的のためにゴシッププロトコルを使ってクラスタの情報を伝播させています。

クラスターバスはまた、Pub/Subメッセージをクラスター内で伝播させる、あるいはユーザによる手動のフェイルオーバを調整するために利用されます（手動のフェイルオーバとは Redisクラスターによって問題を検知したのではなく、システム管理者が直接実行するものです）。

クラスターノードはリクエストをプロキシすることができないので、`-MOVED` や `-ASK` といったエラーを用いて他のノードにリダイレクトされます。クライアントは理論的にはすべてのノードに自由にリクエストを行ってよく、必要に応じてリダイレクトを受け取るので、クラスターの状態を持つ必要はない。しかし、クライアント側でキーとノードのマップをキャッシュさせることができるならば、性能を改善することができるでしょう。


書き込み安全
---

Redis クラスタはノード間で非同期レプリケーションを行い、最後のフェイルオーバによって暗黙的なマージが行われます。これが意味するところは、すべてのレプリカのデータは最後に選出されたマスタのデータによって置き換えられるということです。パーティションに関して、常にデータを失いうるタイムウィンドウが存在します。しかしながら、これらのウィンドウは多数派のマスターあるいは少数派のマスター、どちらに接続しているかによって大きく異なります。

Redis クラスタは、少数派のマスターに接続しているケースと比較して、多数派のマスターに接続している場合には書き込みを保持しやすくなります。以下は多数派のパーティションに対する書き込みが失われるシナリオの例です。

1. マスターとスレーブの間は非同期のレプリケーションとなっているため、書き込みはマスターに到達したものの、マスターがクライアントに応答を返した時点でスレーブに書き込みが伝達されていないケースが起こりうる。もしマスターがスレーブに書き込みを送出できず死んでしまった場合、一定期間を待ってスレーブが昇格してしまうため、その書き込みは失われてしまう。マスターはクライアントに（書き込み完了の）応答を返すとほぼ同時にスレーブにも書き込みを伝えるため、唐突にマスターが障害となるケースはトータルで考えるとごくまれなものだ。しかし、現実で起こりうるシナリオとして考慮すべきだろう。

2. 理論的には、もうひとつ考慮すべき障害ケースがあります。

* パーティションにおけるマスターが疎通性を失う
* このとき、ひとつのスレーブによってフェイルオーバが行われる
* しばらく待つと、マスターの疎通性が回復する
* クライアントが古いルーティングテーブルに沿って、クラスターにおいて（新しいマスターの）スレーブになる処理が完了しないうちに、古いマスターに対し書き込みを行う

2番目の障害シナリオはほとんど起こらないと言えます。フェイルオーバが起こるだけ長い時間、マスターノードが他の多数派のマスターと通信できないということは、書き込みもできないことを意味します。パーティションが復旧したとしても、他のノードから構成変更を受け入れるために書き込みはしばらくの間拒否されます。この障害シナリオでは、クライアントのルーティングテーブルが古い場合という条件もつきます。

少数派側のパーティションでは、書き込みを失う可能性があるウィンドウがより大きくなります。多数派側のマスターがフェイルオーバした場合には、すべてのマスターへの書き込みが失われる可能性があります。このとき少数派のマスターにひとつ以上のクライアントが接続していたとすると、少なくない数の書き込みが失われるでしょう。

特に、マスターのフェイルオーバは、他の多数派のマスターから `NODE_TIMEOUT` の時間だけ疎通性が失われている場合に限るので、パーティションがそれよりも短い時間で復旧した場合は、書き込みが失われることはありません。`NODE_TIMEOUT` よりも長く続いた場合には、それ以降で少数派側に行われた書き込みは失われます。しかしながら、少数派側の Redisクラスターは多数派との通信が失われて `NODE_TIEMOUT` の時間が経過すると、即座に書き込みを拒否するようになります。つまり、そこから算出できる時間が最大のウィンドウということになります。この時間が過ぎたあとは、書き込みはできないので失われることもありません。


可用性
---

Redisクラスターはパーティションの少数派側では利用できません。とあるパーティションにおける多数派側として、多くのマスターと疎通性が失われたマスターに付随するスレーブを考えるとき、そのクラスターは `NODE_TIMEOUT` に加えて数秒待つことで再度利用可能になるでしょう。この数秒はスレーブが選出されてマスターにフェイルオーバするための時間として必要になります（フェイルオーバはたいてい 1-2秒の間に行われます）。

このことから、Redis クラスタは少数ノードの障害には耐性を持つが、大規模なネットワーク障害に対する可用性が求められるアプリケーションには適さないということが分かります。

例えば、各ノードが 1つのスレーブを持つ N 個のマスターで構成されたクラスターを考えると、多数派側はひとつのノードが利用できなくなっても継続的に利用可能ですし、`1-(1/(N*2-1))` の確率で 2つのノードが利用できなくなっても稼働できます（最初のノードが障害になってから `N*2-1` のノードが存在し、このときレプリカを持たないマスターが障害になる確率は `1/(N*2-1)` です）。

5ノードがそれぞれスレーブを持つ構成を例にとると、2つのノードが利用できなくなったときに `1/(5*2-1) = 11.11%` の確率でクラスターは稼働できなくなります。

Redisクラスターの**レプリカマイグレーション**のおかげで、レプリカは孤立したマスター（レプリカを持たないもの）に移行できるようになり、現実世界におけるクラスタの可用性は改善しました。そのため、障害が起こるたびにクラスタはスレーブの構成を変更し、次の障害に備えることができます。


パフォーマンス
---

Redis クラスターのノードはコマンドを他のノードに転送しませんが、その代わりにキーに対して割り当てられたノードに関する情報を返し、クライアントをリダイレクトさせます。

結果としてクライアントはクラスターの最新の状態と、各キーに対応するノードの情報を得ることになり、適切なノードに対してコマンドを送り、操作を行います。

非同期レプリケーションを採用しているため、ノードは他のノードが書き込みを受信するのを待ちません（`WAIT`コマンドを明示的に実行した場合を除く）

また、複数のキーを扱うコマンドが*近くの*キーのみで動作するので、リシャーディングを除いて、データがノード間で移動することはありません。

通常の操作は単一の Redisインスタンスの場合とほとんど同様に扱われます。これはつまり、N個のマスターノードで構成される Redisクラスターと、単一の Redisインスタンスを N個直列に並べてスケールアウトさせた構成は同等のパフォーマンスを発揮できるということです。同時に、クライアントは各ノードと永続的な接続を維持するように動作するため、クエリの通信はほとんどのケースで 1回の往復で済むでしょう。そのため、レイテンシは、単体つまりスタンドアローンで動作する Redisノードの場合と比べても遜色ないと言えます。

非常に高いパフォーマンスとスケーラビリティを達成しつつ、弱点と呼べる部分に関してもある程度のデータの安全性、可用性を担保することが Redisクラスターのゴールと言えるでしょう。


マージ操作をなぜ回避すべきか
---

Redisクラスターは、Redis のデータ構造的に望ましくないという理由で、まったく同じキーとバリューのペアに関して、複数のノードで異なるバージョンが競合しないよう設計されています。Redis におけるバリューはしばしば大きなサイズとなり、数百万という要素についてリストしたり並べ替えたりという操作も多く行われます。データタイプは複雑ですが、それぞれに意味があります。これらのバリューを転送したりマージすることは、大きなボトルネックになる可能性があります。また、アプリケーション側のロジックで大規模な改修が必要になったり、メタデータを格納するための追加メモリが必要になることもあります。

技術的な制約は問題ではありません。CRDTs(Conflict-free Replicated Data Type) や同期的なレプリケーションによって、Redis に似た複雑なデータ構造を処理させることは可能でしょう。しかしながら、それらの仕組みは Redisクラスターとはまったく別のものになるはずです。Redisクラスターは旧来の非クラスタ―型の Redis を包含し、それらのユースケースにも対応するようにデザインされています。


Redisクラスターの主な構成概要
===

キーの分散モデル
---

キー空間はハッシュされて 16384スロットに分割されるので、最大でクラスターは 16384ノードのマスターを持つことができます（しかし、ノード数は最大でも 1000程度までにしておくことをお勧めする）。

各マスターノードは 16384スロットの一部を受け持つ。クラスターは再構成が進行中でないときは**安定している**と言えます（ここで再構成とは、例えばひとつのノードから他のノードへスロットが移動すること）。クラスターが安定した状態であれば、ひとつのスロットは単一のノードで処理されます（しかしながら、ネットワークの分断や障害の発生時、古いデータの読み込みを許容できるのであれば、読み込みが継続できるようひとつ以上のスレーブによって置き換えることができます）。

基礎となるアルゴリズムは、以下のような形でハッシュのスロットをキーにマッピングします（このルールの例外であるハッシュタグは次の章で扱います）。

    HASH_SLOT = CRC16(key) mod 16384

CRC16 は以下のような仕様です。

* Name: XMODEM (also known as ZMODEM or CRC-16/ACORN)
* Width: 16 bit
* Poly: 1021 (That is actually x^16 + x^12 + x^5 + 1)
* Initialization: 0000
* Reflect Input byte: False
* Reflect Output CRC: False
* Xor constant to output CRC: 0000
* Output for "123456789": 31C3

CRC16 のアウトプットのうち 14ビットが使用されます（上の式が 16384 でモジュロ―演算となっているのは、これが理由です）。

テストでは、CRC16 は 16384 のスロットに対し十分に分散した異なるキーを割り当てることが確認されています。

**メモ**: CRC16 アルゴリズムの実装については付録A を参照してください。


キーのハッシュタグ
---

スロットに関するハッシュの計算には、**ハッシュタグ**を実装するために例外が設けられています。ハッシュタグは複数のキーを同じハッシュスロットに配置するために用いられます。これは、Redisクラスターで複数のキーに対する操作を実装するためのものです。

ハッシュタグを実装するにあたって、あるキーに対するハッシュのスロットは少しだけ工夫して計算されます。
キーが "{...}" という文字列を含む場合、スロットは `{` と `}` の間の文字列だけを使ったハッシュによって算出されます。しかし `{` と `}` の組が複数含まれることもありえるため、以下のようなルールに沿ってアルゴリズムが判断を行います。

* キーに `{` が含まれる
* かつ、`{` の右側に `}` があること
* かつ、最初の `{` と 最初の `}` の間に、少なくとも 1文字が存在すること

このときはキーをハッシュするのではなく、最初の `{` と `}` の間に含まれる文字列のみをハッシュの計算に用います。

例:
* 2つのキー `{user1000}.following` と `{user1000}.followers` は、どちらもスロットを特定するために `user1000` でハッシュされるため、同じスロットになります。
* `foo{}{bar}` というキーは部分文字列ではなく、まとめてハッシュされます。最初の `{` と `}` の間に文字が存在しないためです。
* `foo{{bar}}zap` というキーを考えると、このときは文字列 `{bar` でハッシュされます。
* `foo{bar}{zap}` というキーは `bar` でハッシュされます。アルゴリズムは（空の場合も含めて）最初に `{` と `}` にマッチした結果だけを用いるためです。
* どのような文字列が続く場合でも、`{}` で始まるキーに関してはそのままハッシュされるようなアルゴリズムになっています。バイナリデータをキー名に使いたいときは、この性質が役に立つでしょう。

ハッシュタグの例外を追加するにあたり、Ruby と C言語における `HASH_SLOT` 関数の実装は以下のようになります。

Ruby example code:

    def HASH_SLOT(key)
        s = key.index "{"
        if s
            e = key.index "}",s+1
            if e && e != s+1
                key = key[s+1..e-1]
            end
        end
        crc16(key) % 16384
    end

C example code:

    unsigned int HASH_SLOT(char *key, int keylen) {
        int s, e; /* start-end indexes of { and } */

        /* Search the first occurrence of '{'. */
        for (s = 0; s < keylen; s++)
            if (key[s] == '{') break;

        /* No '{' ? Hash the whole key. This is the base case. */
        if (s == keylen) return crc16(key,keylen) & 16383;

        /* '{' found? Check if we have the corresponding '}'. */
        for (e = s+1; e < keylen; e++)
            if (key[e] == '}') break;

        /* No '}' or nothing between {} ? Hash the whole key. */
        if (e == keylen || e == s+1) return crc16(key,keylen) & 16383;

        /* If we are here there is both a { and a } on its right. Hash
         * what is in the middle between { and }. */
        return crc16(key+s+1,e-s-1) & 16383;
    }


クラスターノードの属性
---

すべてのノードはそれぞれ異なった名前を持ちます。ノードの名前は 160ビットのランダムな数字によって 16進数で割り当てられ、ノードがはじめに起動したときに計算されます（ /dev/urandom を使います ）。
ノードは設定ファイルに ID を保存し、設定ファイルをシステム管理者が削除するか、あるいは`CLUSTER RESET` コマンドによって*ハードリセット*されるまで、その後ずっと同じ ID が使われます。

ノードの ID はクラスターの中でノードを特定するためのものです。
ノードは ID を変えることなく、IPアドレスを変化させることができます。クラスターはバス上でゴシッププロトコルを用いて、IP やポート、構成の変化を検出します。

ID が各ノードに割り当てられた唯一の情報というわけではありませんが、常に一定の値を示すものは他にありません。各ノードは後述するように幾つかの情報も持ちます。いくつかは、特定のノードに関する詳細に関するもので、クラスタの中で一貫した値となっています。その他、ノードの監視情報などは各ノードがローカルに保持します。

すべてのノードは、クラスター内で認識している他のノードに関する情報も持ちます。ノードID、IPアドレスやポート、フラグセット、`slave` フラグの場合はどれがマスターか、最後に ping された時間および pong を受け取った時間、現在の*エポック設定*（これはあとで説明します）、接続の状態、最終的に割り当てられたスロットなどです。

[フィールドの詳細](http://redis.io/commands/cluster-nodes) は `CLUSTER NODES` ドキュメントに記載されています。

`CLUSTER NODES`コマンドはどのノードにも送ることができ、クラスターの状態と、クエリを受けた各ノードが持っているローカルな情報を返します。

以下は `CLUSTER NODES` コマンドのサンプルで、小規模な 3ノードのクラスターでマスターにコマンドを送ったときの例です。

    $ redis-cli cluster nodes
    d1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364
    3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729
    d289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095

ここで順に並んでいるフィールドは、ノードID、アドレス:ポート、フラグ、最後に ping された時間、pong を受けとった時間、エポック設定、接続の状態、スロットです。
各フィールドの詳細は、言及すべき Redisクラスターの一部として今後補足していきます。


クラスターバス
---

すべての Redisクラスターのノードは、他のノードからコネクションを受けるため、追加の TCPポートが必要になります。このポートは、通常クライアントからコネクションを受けるためのポート番号に固定値を加えた値をとります。Redisクラスターでは、通常のポート番号に 10000 を加えた値を使います。例えばクライアント用のポートが 6379 でリッスンしている場合、16379 がクラスターバス用に必要となります。

ノード間のやりとりはクラスターバスとそのプロトコル（異なるタイプとサイズのフレームで構成されるバイナリプロトコル）を使って排他的に行われます。このプロトコルを使って Redisクラスターのノードが他のソフトウェア等とやりとりすることは想定されていないため、ドキュメントでは説明していません。もし詳細を知りたい場合は `cluster.h` や `cluster.c` が該当するソースコードになりますので、確認するとよいでしょう。


クラスターのトポロジー
---

Redisクラスターはフルメッシュ構造であり、TCPコネクションを用いて各ノードはそれぞれ他のすべてのノードに接続します。

Nノードの構成を考えるとき、すべてのノードは N-1 の外向きの TCPコネクションと同時に N-1 の被接続のコネクションも持ちます。

これらの TCPコネクションは必要に応じて作られるのではなく、常に維持されます。

ノードは、クラスターバス上で ping に対して pong を返すのですが、このとき疎通性が失われたことを検知するために長い時間待つのではなく、もう一度コネクションを張り直すことを試します。

**ノードは通常通りに動いているときに多数のメッセージを交換することを避け、代わりにゴシッププロトコルで構成をアップデートする仕組みを用いる**ので、フルメッシュのコネクションを保持していても、交換されるメッセージが指数関数的に増大することはありません。


ノードのハンドシェイク
---

ノードはクラスターバス上のポートで常にコネクションを受け入れていて、たとえ通信先のノードが信頼されていないものであったとしても、ping を受け取れば応答を返す。
しかし、パケットを受信したノードがクラスターに所属していない場合、そのパケットは破棄されます。

ノードは以下の方法でのみ他のノードをクラスターの一部として扱います。

* `MEET` メッセージを表明すること。このメッセージは `PING` と同じようなものではあるものの、受け取ったノードは、このメッセージによってクラスターの一部であることを認識する。ノードはシステムの管理者が以下のコマンドを実行した**ときにのみ** `MEET`メッセージを送出する。

    CLUSTER MEET ip port

* とあるノードを考えた時そのノードは、すでに信頼済みのノードによってゴシップ（訳注: P2P におけるピア間の通信）された場合、クラスターの一部として登録される。つまり、例えば A が B を認識していて、B が C を認識しているとき、B はゴシップメッセージを A と C に送信する。このとき A は C をネットワークの一部として認識し、C に接続を試みる。

これはつまり、既存のグラフ構造にノードを追加した場合、自動的にすべてのノードが接続された結果が得られることを意味しています。システム管理者によって信頼関係が確立される必要がありますが、クラスターは他のノードを自動検出することができます。

この仕組みはクラスターをより堅牢にする上、IPアドレスの変更やネットワークに関連したイベントによって異なる Redisクラスターが混在してしまうことも防ぎます。


リダイレクションとリシャーディング
===

MOVED リダイレクション
---

Redisクライアントは、スレーブノードも含めてすべてのノードにクエリを送出することができます。ノードはクエリを分析し、処理できるもの（クエリが単一キーか、あるいは複数キーだがすべてが同じスロットにある）ならば、キーを処理すべきノードを探します。

もしスロットがそのノードに割り当てられていた場合、クエリはそのまま処理されます。そうでない場合は内部でノードのマッピングを確認し、以下のような MOVED エラーを返します。

    GET x
    -MOVED 3999 127.0.0.1:6381

このエラーには、キーのスロット（3999）およびクエリを処理すべき IPアドレスとポートの組が含まれています。クライアントは指定されたアドレスとポートに対し、もう一度クエリを投げる必要があります。
留意すべき点として、クライアント側でクエリを他のノードに再送する段階で時間を要し、その間にクラスターの構成が変わってしまった場合、再送した先のノードが再度 MOVEDエラーを返す可能性があります。また、最初に通信したノードが最新の情報を持っていないケースでも同じような事象が起こりうるでしょう。

したがって、クラスターのノードから見た視点では ID によって各ノードが識別されますが、スロットとノードのマッピングを返すことでインターフェイスを簡略化しようとしています。

クライアントは、必須ではないものの、スロット3999 が 127.0.0.1:6381 に割り当てられているということを覚えておくべきです。それによって新しいコマンドを実行する必要が出てきたとき、キーをハッシュしてスロットを計算するだけでよく、正しいノードを選択できる確率が高まるでしょう。

加えて、MOVED のリダイレクトが発生した時に `CLUSTER NODES` あるいは `CLUSTER SLOTS`コマンドでクライアント側のクラスターレイアウトを丸ごとリフレッシュすることも考えられます。リダイレクトが発生するときには 1つではなく複数のスロットが再割り当てされたと考えられますので、速やかに情報を更新することはほとんどの場合でベストな戦略です。

なお、クラスターが安定状態（実施中の変更がない）のときは、最終的にすべてのクライアントがスロットとノードのマッピングを保持し、効率的に、リダイレクトすることなく直接ノードにアクセスし、これによって余分な経路や単一障害点を取り除くことができるでしょう、

クライアントは後述するように **-ASKリダイレクションを正しく取り扱わなくてはいけません**。そうでない場合、Redisクラスターに対応したクライアントとは言えません。


クラスターのオンライン再構成
---

Redisクラスターはオンラインでノードを追加したり削除することができます。追加も削除も、突き詰めれば同じ操作で、とあるノードから別のノードへスロットの割り当てを移動するということです。クラスター内のスロットをリバランス（再割り当て）する場合と同様、基本的な仕組みという意味では、ノード追加も削除も同じ方法を用いています。

* 新しくノードを追加するためには、空のノードを追加し、クラスターが既存のノードから幾つかのスロットを移動させます。
* ノードの削除では、割り当てられたスロットを他のノードに移動させます。
* リバランスでは、スロットがノード間で移動します。

この実装の中核は、スロットを移動させる機能と言えます。より実用的な観点からは、スロットはつまりキーの集合なので、クラスターが実施していることはキーの移動ということになります。スロットの移動とは、スロットにマッピングされるハッシュ値に関するキーすべてを移動させることです。

この挙動を理解するために、ノードにおけるスロットのマッピングテーブルを操作するための `CLUSTER` のサブコマンドを見ていきましょう。

以下のサブコマンドが利用できます（特にこのケースで役に立つわけでは無いが）。

* `CLUSTER ADDSLOTS` slot1 [slot2] ... [slotN]
* `CLUSTER DELSLOTS` slot1 [slot2] ... [slotN]
* `CLUSTER SETSLOT` slot NODE node
* `CLUSTER SETSLOT` slot MIGRATING node
* `CLUSTER SETSLOT` slot IMPORTING node

最初の 2つのコマンド `ADDSLOTS` と `DELSLOTS` は、単純にスロットを割り当て（もしくは除去）するために使われます。スロットの割り当てとは、指定されたスロットに関する情報を保持しつつ応答するよう、マスターノードに指示を出すものです。

スロットがアサインされたら、構成の伝達セクションで後述するように、ゴシッププロトコルでそれを周知します。

`ADDSLOTS` は多くの場合、新しいクラスターがゼロから作られたときに各マスターで 16384種類のスロットを割り当てるときに使われます。

`DELSLOTS` は主に手動によるクラスターの構成変更、あるいは実際にはまれだと思うが、デバッグ用途でも使われます。

`SELSLOT` サブコマンドは、`SELSLOT <slot> NODE` のような形で用いるが、特定の ID のノードにスロットを割り当てるときに使われます。その他、ノードは 2つの特別なステータス `MIGRATING` と `IMPORTING` になることがあります。これらの 2つのステータスはスロットを移動するときにみられます。

* スロットが MIGRATING になっているとき、ノードはキーが存在する限りスロットに関するすべてのクエリを受け付けるが、そうでない場合は `-ASK` リダイレクションとして応答し、移動先のノードを返す。
* スロットが IMPORTING のとき、ノードはスロットに関して `ASKING` コマンドで行われたクエリに応答します。もしクライアントが `ASKING` コマンドで呼び出していない場合、クエリは通常と同じように、`-MOVED` エラーで実際にスロットが割り当てられたノードにリダイレクトさせる。

この動作を明確にするために、以下の例を考えましょう。今ここに 2つのマスターノードが存在するとして、それぞれを A, B と呼びます。ここでは 8番のスロットを A から B に移動させるとします。このときは以下のようなコマンドを実行します。

* Bに対して: CLUSTER SETSLOT 8 IMPORTING A
* Aに対して: CLUSTER SETSLOT 8 MIGRATING B

すべての他のノードは、引き続き 8番のスロットに関するクエリはすべてノード "A" にリダイレクトさせます。つまり、以下のようになります。

* 既存のキーに対するすべてのクエリはノード "A" で実行される
* 存在しないキーに対するクエリはすべてノード "B" で処理される。なぜなら "A" が "B" にリダイレクトさせるため。

この方式では、ノードA に新しいキーが作られることはありません。この間、`redis-trib` と呼ばれる特別なプログラムがリシャーディングとクラスターの構成変更を行い、8番のスロットに関する既存のキーをノード間（A から B へ）で移動させます。これには以下のようなコマンドを使います。

    CLUSTER GETKEYSINSLOT slot count

上記のコマンドでは `count` のキーを取得します。すべてのキーが返ってくると、`redis-trib` はノード "A" に `MIGRATE` コマンドを送信し、それによって A から B へのキーの移行はアトミックに行われます（両方のインスタンスで、ほとんどの場合で非常に短い時間ではあるがロックされ、その間に競合が発生しないようにキーが移行される）。`MIGRATE` は以下のように動作します。

    MIGRATE target_host target_port key target_database id timeout

`MIGRATE` のときは対象のインスタンスに接続を行い、順次キーを送信します。OK が返ってきたら、古いキーを削除します。外部のクライアントから見たとき、キーは A か B どちらかに存在するということになります。

Redisクラスターではデータベースを 0 以外で指定する必要はありません。しかし `MIGRATE` は一般的なコマンドであり Redisクラスター以外のタスクでも必要とされます。`MIGRATE` は長いリストのような複雑なキーであっても、可能な限り高速に動作するよう最適化されています。しかし、アプリケーションからデータベースを見たときにレイテンシの制約がある場合、大きなキーを含む場合にクラスターの再構成を行うことは賢明とは言えません。

移行のプロセスが完了したとき、`SETSLOT <slot> NODE <node-id>` コマンドは 2つのノードに対し、通常の状態に戻るよう完了を伝えます。同じコマンドが、新しい構成の自然な伝播を待たずに全ノードに送信されます。


ASKリダイレクション
---

前章で ASKリダイレクションについて触れました。なぜ単純な MOVEDリダイレクションだけではダメなのでしょうか。それは、MOVED が永続的に異なるノードでスロットが提供されることを示すものであり、その次のクエリは指定されたノードに送出されるべきだからです。ASK は指定されたノードに次のクエリを送るというだけものです。

例えば、あるキーに関する 8番のスロットが A に存在していたとすると、クライアントは常に A に問い合わせを行い、必要に応じて B にも行います。この事象は 16384スロットのうち同時に 1つしか起こらないので、パフォーマンスへの影響は限定的で許容範囲と言えるでしょう。

クライアントの挙動について、必ずノード A にアクセスしてからノード B への試行を行うようにしなくてはなりません。クライアントはクエリを送る前に ASKING コマンドを送出し、このときノード B は IMPORTING になっているスロットでのみ対応できます。

基本的に ASKING コマンドは IMPORTING になっているスロットへのクエリに対し、1度きりのフラグという性質を持ちます。

クライアントから見た時の、ASKリダイレクションの性質は以下の通りです。

* ASKリダイレクションを受け取ったら、指定されたノードに対し、そのクエリだけをリダイレクトさせる。ただし、後続のクエリは引き続き古いノードに送る。
* ASKING コマンドを添えてリダイレクトのクエリを送る。
* ローカルに保持しているマッピングテーブルは更新しない。

スロットの移行が完了したら、ノード A は MOVEDメッセージを返し、クライアントはマッピングテーブルを更新することになります。例を挙げれば、8番のスロットに対し新しい IPアドレスとポートの組を割り当てて返すということです。
なお、もしクライアントに不具合がありマッピングを意図したよりも早く更新してしまった場合、ASKING コマンドを送らないので問題になることは無いが、ノード B はクライアントにノード A への MOVEDリダイレクションエラーを返すでしょう。

スロットの移行は、似たような内容になりますが異なる形で `CLUSTER SETSLOT`コマンドのドキュメントでも解説しています。


クライアントにおける初回のコネクションとリダイレクションの扱い
---

もちろん、クライアントの実装としてスロットに関する構成（スロットとノードのマッピング）をメモリに記憶せず、リダイレクトされることを期待してランダムなノードに接続するといった実装は可能だが、極めて非効率です。

クライアントはスマートに処理を行うため、スロットの構成を記憶しておくべきでしょう。しかし、この構成は *必ずしも* 最新であるとは言えません。間違ったノードにアクセスした場合、リダイレクトが返ってくるだけなので、クライアント側から見て情報をアップデートするトリガーとして考えるべきです。

クライアントは以下のようなシナリオで、スロットとノード全体のマッピングのリストを取得することになります。

* 起動時、スロットの構成を初期化するため
* `MOVED`リダイレクションが返ってきたとき

ここでクライアントは `MOVED`リダイレクションが返ってきたスロットだけを更新することもできます。ただし、たいていの場合は複数のスロットが一度に変更されます（たとえばスレーブがマスターに昇格したとき、古いマスターに割り当てられたスロットがすべて移動する）。こうした点を考えて、`MOVED`リダイレクションが返ってきたときにはゼロベースで全体のマッピングを更新するように実装した方が、より簡単でしょう。

スロットの構成を取得するとき、Redisクラスターはパースを必要としない `CLUSTER NODES`コマンドの代わりに、クライアントにとって本当に必要な情報だけを返します。

この新しいコマンドは `CLUSTER SLOTS` と呼ばれ、スロットの範囲、その範囲に割り当てられたマスタおよびスレーブノード、といった情報を配列で返します。

以下が `CLUSTER SLOTS` の実行例です。

```
127.0.0.1:7000> cluster slots
1) 1) (integer) 5461
   2) (integer) 10922
   3) 1) "127.0.0.1"
      2) (integer) 7001
   4) 1) "127.0.0.1"
      2) (integer) 7004
2) 1) (integer) 0
   2) (integer) 5460
   3) 1) "127.0.0.1"
      2) (integer) 7000
   4) 1) "127.0.0.1"
      2) (integer) 7003
3) 1) (integer) 10923
   2) (integer) 16383
   3) 1) "127.0.0.1"
      2) (integer) 7002
   4) 1) "127.0.0.1"
      2) (integer) 7005
```

この応答の中で、はじめの 2つのサブ要素はスロットの範囲の開始と終了を示します。続いて、アドレスとポートの組です。最初の組はマスター、続く残りの組は同じスロットに割り当てられたスレーブノードです。エラーとなっているスロット（FAILフラグがセットされている等）は含まれません。

例えば一番最初を見ると、スロットとして 5461 - 10922 が返され（これが開始と終了）、127.0.0.1:7001 がマスターになっています。また、スレーブは 127.0.0.1:7004 であり、これはリードオンリーでアクセスできます。

`CLUSTER SLOTS`は 16384 のスロットすべてを応答に含めることは保証していません。クラスターに何らか問題がある場合、クライアントがマッピングテーブルを初期化するときには NULLオブジェクトで埋められます。その上で、ユーザがそのスロットに対するコマンドを実行しようとしたとき、エラーとして報告します。

このような場合、クライアントはそのままスロットが未割り当てであることをエラーとして報告する前に、スロットの構成が修正されている可能性を考慮し、再度構成情報を取得できないか試行するべきです。


複数のキーに関する操作
---

ハッシュタグのおかげで、クライアントは複数のキーを扱うことができます。例えば以下のようなことができます。

    MSET {user:1000}.name Angela {user:1000}.surname White

ただし、キーが属するスロットがリシャーディングの対象になっている場合、複数のキーを扱えないことがあります。

もう少し詳しく説明すると、リシャーディング中であっても指定したすべてのキーが同じノード上（移動元、移動先、どちらでも）に存在していた場合は、利用することができます。

複数のキーを考えた時に、いくつかのキーが存在しない、あるいはリシャーディング中で移動元と移動先に分離している場合、`-TRYAGAIN`エラーが返されます。クライアントは時間を置いてリトライするか、エラーを返すことになります。

スロットの移行が完了次第、引き続き複数キーに関する操作はまた利用できるようになります。


スレーブノードを用いて読み込みをスケールさせる
---

通常、スレーブノードは受け取ったコマンドに基づいて適切なスロットを持つマスターにリダイレクトさせるのですが、クライアントは `READONLY`コマンドを用いてスレーブにアクセスし、読み込みをスケールさせることができます。

`READONLY` はスレーブノードに対し、クライアントが書き込みを行わないこと、多少古いデータであっても許容できるということを伝えます。

コネクションが読み込み専用であるときは、指定されたキーがスロットに含まれない場合のみリダイレクトを行います。これは以下の場合で発生します。

1. そのスレーブのマスターに割り当てられていないスロットに対し、クライアントがコマンドを送った場合
2. リシャーディングなどで構成が変更されており、以前割り当てられていたが移行済みのスロットに対してコマンドが送られた場合

このときは、前章でも触れたようにクライアントがスロットのマッピングを更新すべきです。

読み込み専用については、`READWRITE`コマンドを使うと終了することができます。


障害耐性（フォールトトレランス）
===

ハートビートとゴシップメッセージ
---

ノードは継続的に ping と pong のパケットをやりとりします。これらの 2種類のパケットは同じ構造になっており、いずれも重要な構成情報を含みます。違いはメッセージタイプのフィールドだけです。ここでは ping と pong パケットの総称として *ハートビートパケット* と呼びます。

ノードが ping パケットを送出すると、それをきっかけとして受信側でも pong パケットを送り返します。しかし、ping は必ずしも必要ではありません。送り返すのではなく、構成情報を他のノードに送る目的で単に pong パケットを送出することも可能だからです。これは有用な仕組みで、例えば新しい構成情報をいち早く伝える目的で使われます。

毎秒、ノードはランダムに幾つかのノードを選び、ping を行います。つまり各ノードから送出される ping パケット数（および応答の pong パケット数）は、クラスター内のノード数に関わらず一定になります。

しかし全てのノードは、ping を送出してこない、もしくは pong を受け取ってから一定の時間（`NODE_TIMEOUT` の半分）が経過している場合に、それらのノードに ping を送ります。また、経過時間が `NODE_TIMEOUT` に達する前に TCPコネクションの確立を試行します。TCPコネクションに問題が生じたことによって疎通性が失われ、まだ問題を認識されていない可能性があるからです。

全体で交換されるメッセージ数は、もし `NODE_TIMEOUT` が小さな値で、かつノード数 N が非常に大きい構成の場合、かなりのものになります。すべてのノードは `NODE_TIMEOUT` の半分の時間が経過する毎に、情報を持ち合わせていないノードすべてに接続を試行することになるからです。

たとえば 100ノードのクラスタでタイムアウト値を 60秒に設定した場合、すべてのノードは 30秒毎におおむね 99 の ping を送出すると考えることができます。これに沿って単純に算出すると、秒間 3.3 の ping が送出される計算になります。100ノードで掛け算し、クラスター全体では秒間 330 の pingメッセージがやりとりされることになります。

このメッセージを少なくする方法はいくつかありますが、現在までに帯域幅に関する問題は報告されていないため、簡単で直接的なデザインになっています。上の例を改めて考えても、秒間 330 のパケットは実際のところ 100 ノードに分散しているため、各ノードにおけるトラフィックへの影響は微々たるものと言えるでしょう。


ハートビートパケットの中身
---

ping と pong はすべてのパケット（フェイルオーバのためのパケットなど）に共通するタイプのヘッダーと、特別なゴシップセクションを含んでいます。

共通のヘッダーは以下のようなものです。

* ノードID、これは 160ビットの疑似ランダムな文字列でノードが作られたときに一度だけ生成され、以後は不変の値
* 分散アルゴリズムをマウントするための `currentEpoch` と `configEpoch` フィールド（これについては次の章で説明します）。ノードがスレーブの場合、`configEpoch` はマスターの `configEpoch` と一致します。
* ノードのフラグ。スレーブ、マスター、あるいは単体ノードなのか
* ノードが持っているスロットのマッピング。もしスレーブならば、そのスロットのマッピングはマスターが持っているものを意味する。
* 送出元の TCPポート（ Redis がクライアントのコマンドを受け取るポート。クラスターバス上のポートは 10000 を足す ）
* 送信者から見た時のクラスターの状態（ダウンもしくはOK）
* スレーブのとき、送信側ノードにおけるマスターの ID 

ping と pong のパケットはゴシップセクションも持ち合わせています。このセクションでは、送出元のノードが他のノードをどのように見ているか、読み手に情報を提供します。ゴシップセクションは、全体のうちランダムで選択された、既知の幾つかのノードしか情報を含んでいません。ゴシップセクションに記載されるノード数は、クラスターのサイズに比例します。

ゴシップセクションに含まれるノードの情報は、以下のフィールドで構成されます。

* ノードID
* ノードの IP とポート
* ノードのフラグ

ゴシップセクションでは、送信したノードから見た他のノードの状態などを受け取ります。これは障害の検知や他のノードをクラスター内で検出するために用いられます。


障害時の挙動
---

Redisクラスターにおける障害の検知とは、特定のマスターあるいはスレーブノードが、多数のノードから見て疎通性が無くなったと判断されたときであり、そのときは必要に応じてスレーブがマスターに昇格します。スレーブの昇格ができないときは、クラスターは状態をエラーに変更し、クエリを受け取らないようにします。

すでに述べられているように、各ノードは他のノードのフラグをリストとして持ちます。障害を検出するためのフラグは 2種類あり `PFAIL` と `FAIL` です。`PFAIL` は *障害の可能性がある* ことを示し、未知の障害を意味します。`FAIL` はノードが障害になっており、決められた時間において多数のマスターから確認が行われた結果です。

**PFAIL フラグ**

とあるノードから見たときに特定のノードが `NODE_TIMEOUT` の時間、疎通しないことが確認できると、`PFAIL` フラグを付与します。マスター、スレーブ、それぞれの役割によらず `PFAIL` をつけることができます。

疎通性が無い状態とは、つまり **アクティブな ping**（送信した ping に応答がない状態）が `NODE_TIMEOUT` の時間継続しているということです。この仕組みでは当然、`NODE_TIMEOUT` はネットワークのラウンドトリップタイムより十分大きくなくてはなりません。通常のオペレーションの中で信頼性を保つため、ping に応答がない時間が `NODE_TIMEOUT` の半分に達した時点でノードは接続を再試行します。この仕組みによってコネクションは常に状態が保たれ、異常なコネクションによる誤検知なども起こらないようになっています。

**FAIL フラグ**

他のノードに関する `PFAIL` フラグそれ自体については、すべてのノードが持ち合わせている情報ですが、スレーブの昇格を行う根拠にするには少し足りません。ノードがダウンしていると判断するためには、`PFAIL` から `FAIL` への変化が必要です。

ハートビートの章で触れたように、すべてのノードはランダムに選ばれた幾つかのノードの状態などを含め、ゴシップメッセージを他のノードに対し送出します。すべてのノードは結果として、すべての他のノードのフラグを持つということになります。すべてのノードにおいて、検出された障害を他のノードに伝えることができる仕組みである、と言えるでしょう。

`PFAIL` は以下の条件を満たしたとき、`FAIL` として判断されます。

* とあるノードを A、`PFAIL` フラグのついたノードを B とする
* ノードA はゴシップメッセージを通じてノードB に関する状態をまとめ、多くのマスターから見た時にどのような状態であるかを確認する
* `PFAIL` もしくは `FAIL` が多数派であり、`NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT` だけの時間が経過している（現時点の実装では、検証のための値は 2 となっている。つまり、先の式の結果は `NODE_TIMEOUT` の 2倍の値である）

これらの条件を満たしたとき、ノードA は

* ノードを `FAIL` とする
* `FAIL` メッセージを疎通可能なすべてのノードに送る

`FAIL` メッセージは、状態が `PFAIL` であるか否かに関わらず、受信したすべてのノードにおいて `FAIL` のフラグをセットさせます。

なお、*FAIL フラグは一方向*です。この意味は、ノードが `PFAIL` から `FAIL` になることはあっても逆はありえず、`FAIL` フラグは幾つかの条件下でクリアされるのみだ、ということです。

* ノードがスレーブであり、疎通可能になっていること。このケースではスレーブであることが条件に含まれているため、フェイルオーバは発生せず、`FAIL` フラグをクリアするだけの結果となる。
* ノードがマスターではあるもののスロットの割り当てが無く、疎通可能になっていること。この場合は割り当てられたスロットが無いためクラスターに参加していないということであり、`FAIL` フラグは単にクリアされるだけとなる。その後、引き続きクラスターへの参加を待つことになる。
* ノードがマスターで疎通可能になっているが、しばらくの時間（`NODE_TIMEOUT` かける N ）が経過しており、スレーブの昇格が起こっていない場合。このときはフェイルオーバなどを続けるよりも、クラスターに再加入させた方が良いと判断される。

`PFAIL` から `FAIL` への変化においては、弱い合意の形を取ります。

1. ノードは、他のノードから見た情報を集め、多くのノードから "合意" が取れれば、それはつまり異なるノード、異なる時間における確認の結果ということになるので、より多くのマスターが合意したとみなす。しかしながら、障害は一定の時間枠を設けて多数のノードが合意することで検知するデザインになっているので、個別の障害の通知が古くなったときには破棄される。

2. すべてのノードは `FAIL` を認識したとき、他のノードすべてに `FAIL` メッセージを通知する義務がある。しかし、すべてのノードに確実に行き渡ることは保証されない。たとえば `FAIL` が検知されたけれど、その理由が他のノードにアクセスできないから、といったケースもありえる。

しかし、Redisクラスターの障害検知は活性の必要事項を持ちます。結果としてすべてのノードの合意を取り付ける必要があります。スプリットブレイン（訳注: 何らかの理由で複数のノードが自分をマスターとして認識してしまうこと）が起こりうる 2つのケースが考えられます。いくつかの少数のノードが特定のノードを `FAIL` だと判断したとき、あるいは逆に少数のノードが特定のノードが `FAIL` でない、と判断したとき。これらのケースでも、クラスターは最終的には単一の状態を持つようになっています。

**ケース1**: 多くのマスターが特定のノードを `FAIL` と判断し、障害検知され *連鎖的な影響が発生し*、他のすべてのノードが `FAIL` を認識する。このとき一定の時間幅に達していれば、障害として検知されるべきものである、と言えるだろう。

**ケース2**: 少数のマスターが特定のノードを `FAIL` と判断したとき、スレーブの昇格は起こらない（全員の合意を得られたことを確認してから昇格させるアルゴリズムが使われている）。すべてのノードは `FAIL` フラグを消去する（昇格が `NODE_TIMEOUT` かける N の時間起こらないとき）。

** スレーブの昇格において、`FAIL` フラグはアルゴリズムの一部を実行するための契機に過ぎません**。スレーブからマスターへの疎通が無くなったとき、スレーブが独自に昇格を行うといったことがあり得ます。そのときは多数のマスターに確認を求めます。しかし `PFAIL` から `FAIL` への複雑な変化において、弱い合意、および `FAIL` メッセージが最短で伝播されるという挙動は、実用的な実装です。これらの仕組みによって、障害が検知されたノードで継続して書き込みが行われることを回避できます。これは Redisクラスターを使うアプリケーションから見たときには望ましい機能です。また、部分的な問題（マスターは他のマスターから疎通できるなど）によって発生しうる、スレーブによる誤った選挙も回避できます。


再構成の挙動、伝播、およびフェイルオーバについて
===

クラスターの epoch
---

Redisクラスターは Raftアルゴリズムの "term" と似たコンセプトを用いています。Redisクラスターでは、この term に相当するものを代わりに epoch と呼んでおり、イベントのバージョンを増分で管理していくために使われています。これにより、複数のノードが競合する情報を発信してしまったときに、どの情報が最も最新のものなのか判断することができます。

`currentEpoch` は 64ビットの符号なし整数です。

Redisクラスターを作成すると、マスターとスレーブいずれにおいても、`currectEpoch` を 0 にセットします。

他のノードからパケットを受け取るたび、送信元の epoch（クラスターバスメッセ―ジのヘッダーに含まれる）が手元の epoch より大きければ、`currentEpoch` を受け取った epoch で更新します。

この仕組みにより、すべてのノードがいずれは最新の `configEpoch` に追いつき、同意するということになります。

この情報はクラスターのステータスが変化したとき、あるいはノードが何らかのアクションを起こす時に合意を取る目的で利用されます。

現時点ではスレーブの昇格のみとなっており、これについては次のセクションで説明しています。基本的に epoch はクラスターの論理的な時刻情報であり、小さい方の epoch よりも 1 だけ大きな値をとります。


構成における epoch
---

各マスターはスロット群のマッピングとは別に、ping/pong パケットを用いて自身の `configEpoch` も配布しています。

この `configEpoch` は、新しいノードが作成されるとマスターで 0 になります。

新しい `configEpoch` はスレーブの選挙中に作成されます。スレーブは障害になったマスターを置き換える際 epoch を加算し、他の多数のマスターから合意を取り付けようとします。合意が得られると新しく独自の `configEpoch` が作られ、その新しい `configEpoch` でマスターとして動きます。

次の章で説明するように、`configEpoch` は異なるノードがそれぞれで分岐した構成を取ろうとしたときに、競合を解消する助けとなります。

スレーブもまた `configEpoch` を ping/pong パケットで配布しますが、その中身はマスターのものです。ただしこれにより、他のインスタンスから見て古い状態になっていることが検知できます（マスターノードは古い状態のノードには投票しません）。

`configEpoch` の変更を受け取ると、その値は永続的なものとして node.conf に保存されます。これは `currentEpoch` に関しても同様です。これらの 2つの値は `fsync-ed` でノードが次の動作に移る前にディスクに書き込まれます。

このように `configEpoch` の値はフェイルオーバ時に単純なアルゴリズムで生成され、常に最新であり、独立していて、加算的なものとして扱われます。


スレーブの選挙と昇格
---

スレーブの選挙と昇格は、昇格についてはマスターの助けを借りながら、スレーブによって行われます。少なくとも 1つのスレーブがマスターになる条件を満たしており、そのスレーブから見てマスターが `FAIL` 状態になると、スレーブの選挙が発生します。

スレーブが昇格を行うためには、選挙を行って選ばれなくてはなりません。マスターが `FAIL` 状態なのであれば全てのスレーブで選挙を開始することができますが、選ばれて昇格するスレーブはたったひとつです。

スレーブは以下の条件で選挙を開始します。

* スレーブのマスターが `FAIL` 状態である
* マスターに 1つ以上のスロットが割り当てられている
* レプリケーションの接続が一定時間以上切れていて、昇格しようとしているスレーブのデータが比較的新しいこと。この時間はユーザが設定可能なものです。

スレーブが選ばれるための最初のステップは、`currentEpoch` カウンターを加算し、マスター群に投票を依頼することです。

投票はスレーブによって依頼され、`FAILOVER_AUTH_REQUEST` パケットですべてのマスターに同報されます。そのあと `NODE_TIMEOUT` の 2倍の時間だけ応答を待ちます（ほとんどの場合は 2秒です）。

マスターが一度投票すると、`FAILOVER_AUTH_ACK` で応答を返し、以降は `NODE_TIMEOUT * 2` の時間、同じマスターに関連するスレーブには投票しません。この間は、同じマスターに関連する他の承認リクエストには応答しないということです。これによって安全が保証されるわけではありませんが、ほとんど同じ時間帯に複数のスレーブが選出されてしまうこと（たとえ `configEpoch` が違っても）は防げるので、望まない事態は避けられるでしょう。

スレーブは、投票を依頼した時点における `currentEpoch` よりも古い `AUTH_ACK` 応答を破棄します。これによって、古い投票のカウントを回避します。

スレーブが多数派のマスターから ACK を受け取ったとき、投票で選出されたものとして扱われます。もし `NODE_TIMEOUT` の 2倍の時間だけ（多くの場合 2秒）待っても多数派の応答が得られない場合、投票は終了され `NODE_TIMEOUT` の 4倍の時間（たいてい 4秒）だけ待って改めて試行されます。


スレーブの順位
---

マスターが `FAIL` 状態になるとすぐ、スレーブは選挙に備えて短い待機時間をとります。この時間の計算式は以下です。

    DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds +
            SLAVE_RANK * 1000 milliseconds.

この決まった待機時間は、クラスター内で `FAIL` 状態が伝播するのを待つためのものです。これを待たないと、マスターが `FAIL` 状態を検知しないままに応答を行い、結果として投票を拒否することになってしまうかもしれません。

ランダムな遅延時間を設定するのは、まったく同じタイミングで選挙が開始することを防ぐためです。

`SLAVE_RANK` はスレーブの順位で、マスターからレプリケートされたデータの処理量に関するものです。スレーブは、マスターが障害になったとき（ベストエフォートの）順位を決めるためにメッセージを交換します。
もっとも最新のデータを持っているスレーブが 0位、その次が 1位、といった形です。
この方法では、もっとも最新のデータを持っているスレーブが、まず選挙を試行します。
順位の並びは厳密なものではありません。より高い順位のスレーブが選挙に失敗したとき、他のスレーブがすぐに試行します。

いずれかのスレーブが選挙で選ばれたときは、既存のマスターよりも高い値の `configEpoch` を持ちます。スレーブは ping/pong パケットでマスターになったことを伝播し、`configEpoch` とともに割り当てられたスロットを伝えます。

他のノードにおける再構成を迅速に行うため、pong パケットは他のすべてのノードに同報されます。その時点で到達できないノードは、最終的に ping もしくは pong パケットを受信したとき、あるいはハートビートによって古い状態を検知したときに `UPDATE` パケットを受信して再構成されます。

他のノードは、以前と同じスロットの割り当てを持ち、以前よりも大きな値の `configEpoch` を持っている新しいマスターを検出すると、再構成を行います。以前のマスターのスレーブ（もしくは、再加入した場合はフェイルオーバしたマスター）は構成の変更は行わず、新しいマスターからレプリケーションするよう再構成します。ノードがクラスターに再加入したときの挙動は、次の章で説明します。


スレーブの投票依頼に対するマスターの応答
---

前章では、スレーブの選挙を扱いました。この章ではスレーブから依頼があったときの挙動について、マスターの視点から説明を試みます。

マスターはスレーブから `FAILOVER_AUTH_REQUESTS` の形で投票の依頼を受け取ります。
投票を行うにあたっては、いくつかの条件があります。

1. マスターは各 epoch に対し、1回だけ投票を行い、古い epoch に対しては拒否を返します。すべてのマスターは lastVoteEpoch 値を持ち、この値よりも古い `currentEpoch` が含まれる投票依頼は拒否します。マスターが投票を正しく送ったとき、lastVoteEpoch をアップデートし、ディスクに安全に書き込まれます。
2. マスターは、`FAIL` となっているマスター配下のスレーブにのみ投票します。
3. マスターが保持している `currentEpoch` よりも古い `currentEpoch` を含むようなリクエストは無視されます。これによって、マスターの応答は常に依頼と同じ `currentEpoch` となります。もし同じスレーブが複数回投票の依頼を行い、その中で `currentEpoch` が加算されていた場合、古くて遅延した応答は、新しい投票ではカウントされないことが保証されています。

ルール 3 に従わない場合の問題は以下のような例が考えられます。

マスターの `currentEpoch` が 5 であり、lastVoteEpoch が 1 （何度か投票に失敗すると起こりえます）とします。

* スレーブの `currentEpoch` が 3
* スレーブは epoch 4（3+1）で選挙を試行し、マスターは `currentEpoch` 5 で応答を返しますが、遅延したとします。
* スレーブが再度選挙を試行します。epoch は 5 （4+1）になり、このとき遅延した応答が `currentEpoch` 5 でスレーブに到達し、受理されます。

4. マスターは一度投票を行ってから、`NODE_TIMEOUT * 2` の時間が経過するまで、同じマスター配下のスレーブには投票を行いません。同じ epoch のスレーブが 2つ同時に選出されることはないので、この挙動は厳密には必須ではありません。しかし実際には、他のスレーブが別に新しい選挙を行って選出されてしまう可能性があり、そうなると不要な 2回目のフェイルオーバが発生してしまうので、これを防ぐために他のスレーブに通知するための十分な時間を確保します。
5. マスターは最善のスレーブを選ぶ努力はしません。スレーブのマスターが `FAIL` 状態になり、マスターが投票を行っていない場合、承認の投票を行います。最善のスレーブはほとんどの場合、前章で説明したように*より高い順位*なので、他のスレーブよりも先に選挙を行います。
6. マスターが投票を拒否する時、何らかの応答を返すことはしません。単純にリクエストを無視します。
7. マスターは持ち合わせている `configEpoch` よりも小さい `configEpoch` を送ってきたスレーブには投票しません。スレーブは自身のマスターが持つ `configEpoch` やスロットのマッピングを送ります。これはつまり、投票を依頼するスレーブはフェイルオーバしたいスロットの構成を知っていて、その構成が投票を行うマスターのものと同じか新しいものではなくてはならない、ということです。

パーティションにおける epoch の実用性、その実例
---

この章では epoch のコンセプトが、パーティションにおいてスレーブの昇格をより頑健にするということを示します。

* マスターが疎通性を失ったとします。このとき 3つのスレーブ A, B, C があります。
* スレーブ A が選挙で選出され、マスターへ昇格しました。
* しかしその後ネットワーク的に分断され、A は多数派からの疎通が確認できなくなりました。
* スレーブ B が選挙で選出され、マスターへ昇格しました。
* 同様に B もまた多数派からの疎通がなくなりました。
* ネットワークの分断が修復され、A が復旧しました。

この時点では B がダウンしているが A が復旧しており、再度マスターになれるはずです（実際のところ `UPDATE` メッセージは都度再構成を促しますが、ここではすべて失われたと仮定します）。このとき、スレーブ C がフェイルオーバによって選出されようと試みます。このときは以下のようになります。

1. C は選挙を試みます。多数派のマスターから見てマスターはダウンしているわけですから、これは成功します。このとき `configEpoch` が加算されます。
2. A はスロットの関係でマスターになることはできません。このとき A が保持している epoch値は古いものになっており、それより新しい epoch値（たとえば B のもの）を持つノードにスロットがアサインされているからです。
3. したがって、すべてのノードは C にスロットがアサインされたものとしてテーブルを更新し、その後クラスターは操作を受け付けるようになります。

次の章では、外れたノードがクラスターに再加入する際には他のノードをすぐに ping するため、再構成の通知が迅速に行われることを説明します。受信側は古い情報を検知し、`UPDATE` メッセージを送信します。


スロット構成の伝播
---

クラスターにおいて、どのスロットが割り当てられているか、そういった情報を伝播させる仕組みは重要です。真新しいクラスターの起動、スレーブが障害になったマスターに代わって昇格したときの構成変更、そのどちらにとっても中核の役割を担っています。

同じ仕組みで、クラスターから長期にわたって外れてしまったノードを合理的に再加入させることができます。

スロットの割り当てに関する構成は、以下のように伝播します。

1. ハートビートのメッセージ。ping/pong パケットの送り元は、常にスロットに関する情報も送ります（スレーブの場合は、そのマスターに関する情報を送ります）。
2. `UPDATE`メッセージ。すべてのハートビートパケットは送信元の `configEpoch` および割り当てられたスロットの情報を含むので、受信側で情報が古いことを検知すると新しい情報を返し、アップデートを促します。

ハートビートの受信側あるいは `UPDATE`メッセージは、ノードに関するスロットのマッピングをシンプルな形で確実に更新するために使われます。新しいクラスターが作成されたとき、ローカルのスロットに関するテーブルは単純に `NULL` で初期化され、したがってはじめは各スロットはノードに紐づきません。このときは以下のような形に見えるでしょう。

```
0 -> NULL
1 -> NULL
2 -> NULL
...
16383 -> NULL
```

ノードは、スロットテーブルを更新するために幾つかのルールに沿って動作します。

**ルール 1**: もしスロットが未割り当て（つまり `NULL`）であり、いずれかのノードが割り当てを要求しているとき、その割り当て要求に沿って自分が持っている情報を更新します。

たとえばノード A からハートビートを受け取り、その A がスロット 1 と 2 を要求していて、epoch の値が 3 であると仮定すると、テーブルは以下のように更新されます。

```
0 -> NULL
1 -> A [3]
2 -> A [3]
...
16383 -> NULL
```

新しいクラスターが作られるとき、システム管理者は手動で（ redis-tribコマンドラインツールなどを使って `CLUSTER ADDSLOTS` コマンドを使い）、各マスターにそれぞれスロットを割り当てる必要があります。その情報はクラスター内で迅速に伝播します。

しかし、これだけではルールは十分ではありません。2種類のイベントによってマッピングは変わりうるからです。

1. フェイルオーバでスレーブがマスターに昇格する
2. スロットがリシャーディングによって異なるノードに割り当てられる

まずはフェイルオーバについて見ていきましょう。フェイルオーバでスレーブがマスターに置き換わるとき、スレーブは epoch を持ち、いずれのマスターよりも大きな値であることが保証されています（そして、過去に生成されたどの値よりも大きいと言えるでしょう）。例えばノードB がノード A のスレーブであり、フェイルオーバのときに epoch が 4 だったとします。まずはじめにハートビートのパケットが（クラスターで見たときに全体に対して）送出され、後述する 2番目のルールによって、受信側はスロットのテーブルを更新します。

**ルール 2**: もしスロットがマスターにすでに割り当てられているときに、別のノードがより大きな値の `configEpoch` を主張しているとき、スロットのテーブルを新しいノードで更新します。

つまり、B がスロット 1, 2 に関して epoch の値 4 のリクエストを送出したとき、受信側から見て以下のようなテーブルに更新されます。

```
0 -> NULL
1 -> B [4]
2 -> B [4]
...
16383 -> NULL
```

生存属性: この 2番目のルールにより、最終的にクラスターの全てのノードは、スロットの割り当て先が必ず一番大きな `configEpoch` を持つようになります。

Redisクラスターにおいて、この仕組みは**フェイルオーバの後勝ち**と呼びます。

リシャーディングにおいても同じことが起こります。ノードがスロットのインポートを完了したとき epoch に加算を行うので、これによって変更がクラスター内で反映されます。


UPDATEメッセージ
---

UPDATEメッセージの挙動について、前章で触れたことは覚えているでしょうか。ノード A は少しの時間を置いてから、クラスターに再加入するでしょう。先の例に沿うと、ハートビートパケットを送出してスロット 1 と 2 の割り当てを、epoch 値が 3 で申請します。すべての受信側は最新の情報を持っているわけですから、確認すると指定されたスロットはノード B に割り当て済みで、より高い値の epoch が見つかるでしょう。これにより、受信側はスロットの最新の構成を含めた `UPDATE` メッセージを A に返します。A は**ルール 2** に沿って情報を更新します。


クラスターへの再加入
---

基本的な仕組みは、クラスターの再加入においても変わりません。引き続き同じ例を用いますが、ノード A は、すでに B がスロット 1, 2 の提供を担っていることを知りました。以前に A に割り当てられていたスロットはその 2つだけだったわけですから、この時点で割り当てられるスロットは 0 になってしまいました。したがって A は**新しいマスターのスレーブとして再構成されます**。

実際のルールは、もう少し複雑です。一般的には、A の再加入には時間を要します。A に割り当てられていたスロットが複数のノードに割り当てられていることが考えられますし、例えばスロット 1 がノード B に、スロット 2 がノード C に割り当てられているかもしれません。

なので、実際のところ*ノードの役割変更のルール*は、**最後のスロットを渡したノードからレプリケーションを行う**というものです。

再構成にあたり、スロットの数は 0 になります。これはつまり、マスターだったノードがフェイルオーバ後はスレーブだったノードのスレーブになる、ということを意味します。しかし、起こりうるすべてのケースを考慮できているはずです。

スレーブもまた、同じです。再構成のときには、そのマスターが最後に扱っていたスロットに関して確認を行い、そのスロットを渡したノードからレプリケーションを行います。


レプリカの移行
---

Redisクラスターはシステムの可用性を高めるため、*レプリカの移行*と呼ばれるコンセプトを取り入れています。マスターとスレーブで構築されたクラスターにおいて単体の障害が複数独立して発生したとき、もしマスタースレーブ間のマッピングが固定だと可用性が必ずしも高く保てない、という考えに基づいて考案されています。

For example in a cluster where every master has a single slave, the cluster
can continue operations as long as either the master or the slave fail, but not
if both fail the same time. However there is a class of failures that are
the independent failures of single nodes caused by hardware or software issues
that can accumulate over time. For example:

* Master A has a single slave A1.
* Master A fails. A1 is promoted as new master.
* Three hours later A1 fails in an independent manner (unrelated to the failure of A). No other slave is available for promotion since node A is still down. The cluster cannot continue normal operations.

If the map between masters and slaves is fixed, the only way to make the cluster
more resistant to the above scenario is to add slaves to every master, however
this is costly as it requires more instances of Redis to be executed, more
memory, and so forth.

An alternative is to create an asymmetry in the cluster, and let the cluster
layout automatically change over time. For example the cluster may have three
masters A, B, C. A and B have a single slave each, A1 and B1. However the master
C is different and has two slaves: C1 and C2.

Replica migration is the process of automatic reconfiguration of a slave
in order to *migrate* to a master that has no longer coverage (no working
slaves). With replica migration the scenario mentioned above turns into the
following:

* Master A fails. A1 is promoted.
* C2 migrates as slave of A1, that is otherwise not backed by any slave.
* Three hours later A1 fails as well.
* C2 is promoted as new master to replace A1.
* The cluster can continue the operations.

Replica migration algorithm
---

The migration algorithm does not use any form of agreement since the slave
layout in a Redis Cluster is not part of the cluster configuration that needs
to be consistent and/or versioned with config epochs. Instead it uses an
algorithm to avoid mass-migration of slaves when a master is not backed.
The algorithm guarantees that eventually (once the cluster configuration is
stable) every master will be backed by at least one slave.

This is how the algorithm works. To start we need to define what is a
*good slave* in this context: a good slave is a slave not in `FAIL` state
from the point of view of a given node.

The execution of the algorithm is triggered in every slave that detects that
there is at least a single master without good slaves. However among all the
slaves detecting this condition, only a subset should act. This subset is
actually often a single slave unless different slaves have in a given moment
a slightly different view of the failure state of other nodes.

The *acting slave* is the slave among the masters with the maximum number
of attached slaves, that is not in FAIL state and has the smallest node ID.

So for example if there are 10 masters with 1 slave each, and 2 masters with
5 slaves each, the slave that will try to migrate is - among the 2 masters
having 5 slaves - the one with the lowest node ID. Given that no agreement
is used, it is possible that when the cluster configuration is not stable,
a race condition occurs where multiple slaves believe themselves to be
the non-failing slave with the lower node ID (it is unlikely for this to happen
in practice). If this happens, the result is multiple slaves migrating to the
same master, which is harmless. If the race happens in a way that will leave
the ceding master without slaves, as soon as the cluster is stable again
the algorithm will be re-executed again and will migrate a slave back to
the original master.

Eventually every master will be backed by at least one slave. However,
the normal behavior is that a single slave migrates from a master with
multiple slaves to an orphaned master.

The algorithm is controlled by a user-configurable parameter called
`cluster-migration-barrier`: the number of good slaves a master
must be left with before a slave can migrate away. For example, if this
parameter is set to 2, a slave can try to migrate only if its master remains
with two working slaves.

configEpoch conflicts resolution algorithm
---

When new `configEpoch` values are created via slave promotion during
failovers, they are guaranteed to be unique.

However there are two distinct events where new configEpoch values are
created in an unsafe way, just incrementing the local `currentEpoch` of
the local node and hoping there are no conflicts at the same time.
Both the events are system-administrator triggered:

1. `CLUSTER FAILOVER` command with `TAKEOVER` option is able to manually promote a slave node into a master *without the majority of masters being available*. This is useful, for example, in multi data center setups.
2. Migration of slots for cluster rebalancing also generates new configuration epochs inside the local node without agreement for performance reasons.

Specifically, during manual reshardings, when a hash slot is migrated from
a node A to a node B, the resharding program will force B to upgrade
its configuration to an epoch which is the greatest found in the cluster,
plus 1 (unless the node is already the one with the greatest configuration
epoch), without requiring agreement from other nodes.
Usually a real world resharding involves moving several hundred hash slots
(especially in small clusters). Requiring an agreement to generate new
configuration epochs during reshardings, for each hash slot moved, is
inefficient. Moreover it requires an fsync in each of the cluster nodes
every time in order to store the new configuration. Because of the way it is
performed instead, we only need a new config epoch when the first hash slot is moved,
making it much more efficient in production environments.

However because of the two cases above, it is possible (though unlikely) to end
with multiple nodes having the same configuration epoch. A resharding operation
performed by the system administrator, and a failover happening at the same
time (plus a lot of bad luck) could cause `currentEpoch` collisions if
they are not propagated fast enough.

Moreover, software bugs and filesystem corruptions can also contribute
to multiple nodes having the same configuration epoch.

When masters serving different hash slots have the same `configEpoch`, there
are no issues. It is more important that slaves failing over a master have
unique configuration epochs.

That said, manual interventions or reshardings may change the cluster
configuration in different ways. The Redis Cluster main liveness property
requires that slot configurations always converge, so under every circumstance
we really want all the master nodes to have a different `configEpoch`.

In order to enforce this, **a conflict resolution algorithm** is used in the
event that two nodes end up with the same `configEpoch`.

* IF a master node detects another master node is advertising itself with
the same `configEpoch`.
* AND IF the node has a lexicographically smaller Node ID compared to the other node claiming the same `configEpoch`.
* THEN it increments its `currentEpoch` by 1, and uses it as the new `configEpoch`.

If there are any set of nodes with the same `configEpoch`, all the nodes but the one with the greatest Node ID will move forward, guaranteeing that, eventually, every node will pick a unique configEpoch regardless of what happened.

This mechanism also guarantees that after a fresh cluster is created, all
nodes start with a different `configEpoch` (even if this is not actually
used) since `redis-trib` makes sure to use `CONFIG SET-CONFIG-EPOCH` at startup.
However if for some reason a node is left misconfigured, it will update
its configuration to a different configuration epoch automatically.

Node resets
---

Nodes can be software reset (without restarting them) in order to be reused
in a different role or in a different cluster. This is useful in normal
operations, in testing, and in cloud environments where a given node can
be reprovisioned to join a different set of nodes to enlarge or create a new
cluster.

In Redis Cluster nodes are reset using the `CLUSTER RESET` command. The
command is provided in two variants:

* `CLUSTER RESET SOFT`
* `CLUSTER RESET HARD`

The command must be sent directly to the node to reset. If no reset type is
provided, a soft reset is performed.

The following is a list of operations performed by a reset:

1. Soft and hard reset: If the node is a slave, it is turned into a master, and its dataset is discarded. If the node is a master and contains keys the reset operation is aborted.
2. Soft and hard reset: All the slots are released, and the manual failover state is reset.
3. Soft and hard reset: All the other nodes in the nodes table are removed, so the node no longer knows any other node.
4. Hard reset only: `currentEpoch`, `configEpoch`, and `lastVoteEpoch` are set to 0.
5. Hard reset only: the Node ID is changed to a new random ID.

Master nodes with non-empty data sets can't be reset (since normally you want to reshard data to the other nodes). However, under special conditions when this is appropriate (e.g. when a cluster is totally destroyed with the intent of creating a new one), `FLUSHALL` must be executed before proceeding with the reset.

Removing nodes from a cluster
---

It is possible to practically remove a node from an existing cluster by
resharding all its data to other nodes (if it is a master node) and
shutting it down. However, the other nodes will still remember its node
ID and address, and will attempt to connect with it.

For this reason, when a node is removed we want to also remove its entry
from all the other nodes tables. This is accomplished by using the
`CLUSTER FORGET <node-id>` command.

The command does two things:

1. It removes the node with the specified node ID from the nodes table.
2. It sets a 60 second ban which prevents a node with the same node ID from being re-added.

The second operation is needed because Redis Cluster uses gossip in order to auto-discover nodes, so removing the node X from node A, could result in node B gossiping about node X to A again. Because of the 60 second ban, the Redis Cluster administration tools have 60 seconds in order to remove the node from all the nodes, preventing the re-addition of the node due to auto discovery.

Further information is available in the `CLUSTER FORGET` documentation.

Publish/Subscribe
===

In a Redis Cluster clients can subscribe to every node, and can also
publish to every other node. The cluster will make sure that published
messages are forwarded as needed.

The current implementation will simply broadcast each published message
to all other nodes, but at some point this will be optimized either
using Bloom filters or other algorithms.

Appendix
===

Appendix A: CRC16 reference implementation in ANSI C
---

    /*
     * Copyright 2001-2010 Georges Menie (www.menie.org)
     * Copyright 2010 Salvatore Sanfilippo (adapted to Redis coding style)
     * All rights reserved.
     * Redistribution and use in source and binary forms, with or without
     * modification, are permitted provided that the following conditions are met:
     *
     *     * Redistributions of source code must retain the above copyright
     *       notice, this list of conditions and the following disclaimer.
     *     * Redistributions in binary form must reproduce the above copyright
     *       notice, this list of conditions and the following disclaimer in the
     *       documentation and/or other materials provided with the distribution.
     *     * Neither the name of the University of California, Berkeley nor the
     *       names of its contributors may be used to endorse or promote products
     *       derived from this software without specific prior written permission.
     *
     * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY
     * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
     * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
     * DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY
     * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
     * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
     * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
     * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
     * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
     * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
     */

    /* CRC16 implementation according to CCITT standards.
     *
     * Note by @antirez: this is actually the XMODEM CRC 16 algorithm, using the
     * following parameters:
     *
     * Name                       : "XMODEM", also known as "ZMODEM", "CRC-16/ACORN"
     * Width                      : 16 bit
     * Poly                       : 1021 (That is actually x^16 + x^12 + x^5 + 1)
     * Initialization             : 0000
     * Reflect Input byte         : False
     * Reflect Output CRC         : False
     * Xor constant to output CRC : 0000
     * Output for "123456789"     : 31C3
     */

    static const uint16_t crc16tab[256]= {
        0x0000,0x1021,0x2042,0x3063,0x4084,0x50a5,0x60c6,0x70e7,
        0x8108,0x9129,0xa14a,0xb16b,0xc18c,0xd1ad,0xe1ce,0xf1ef,
        0x1231,0x0210,0x3273,0x2252,0x52b5,0x4294,0x72f7,0x62d6,
        0x9339,0x8318,0xb37b,0xa35a,0xd3bd,0xc39c,0xf3ff,0xe3de,
        0x2462,0x3443,0x0420,0x1401,0x64e6,0x74c7,0x44a4,0x5485,
        0xa56a,0xb54b,0x8528,0x9509,0xe5ee,0xf5cf,0xc5ac,0xd58d,
        0x3653,0x2672,0x1611,0x0630,0x76d7,0x66f6,0x5695,0x46b4,
        0xb75b,0xa77a,0x9719,0x8738,0xf7df,0xe7fe,0xd79d,0xc7bc,
        0x48c4,0x58e5,0x6886,0x78a7,0x0840,0x1861,0x2802,0x3823,
        0xc9cc,0xd9ed,0xe98e,0xf9af,0x8948,0x9969,0xa90a,0xb92b,
        0x5af5,0x4ad4,0x7ab7,0x6a96,0x1a71,0x0a50,0x3a33,0x2a12,
        0xdbfd,0xcbdc,0xfbbf,0xeb9e,0x9b79,0x8b58,0xbb3b,0xab1a,
        0x6ca6,0x7c87,0x4ce4,0x5cc5,0x2c22,0x3c03,0x0c60,0x1c41,
        0xedae,0xfd8f,0xcdec,0xddcd,0xad2a,0xbd0b,0x8d68,0x9d49,
        0x7e97,0x6eb6,0x5ed5,0x4ef4,0x3e13,0x2e32,0x1e51,0x0e70,
        0xff9f,0xefbe,0xdfdd,0xcffc,0xbf1b,0xaf3a,0x9f59,0x8f78,
        0x9188,0x81a9,0xb1ca,0xa1eb,0xd10c,0xc12d,0xf14e,0xe16f,
        0x1080,0x00a1,0x30c2,0x20e3,0x5004,0x4025,0x7046,0x6067,
        0x83b9,0x9398,0xa3fb,0xb3da,0xc33d,0xd31c,0xe37f,0xf35e,
        0x02b1,0x1290,0x22f3,0x32d2,0x4235,0x5214,0x6277,0x7256,
        0xb5ea,0xa5cb,0x95a8,0x8589,0xf56e,0xe54f,0xd52c,0xc50d,
        0x34e2,0x24c3,0x14a0,0x0481,0x7466,0x6447,0x5424,0x4405,
        0xa7db,0xb7fa,0x8799,0x97b8,0xe75f,0xf77e,0xc71d,0xd73c,
        0x26d3,0x36f2,0x0691,0x16b0,0x6657,0x7676,0x4615,0x5634,
        0xd94c,0xc96d,0xf90e,0xe92f,0x99c8,0x89e9,0xb98a,0xa9ab,
        0x5844,0x4865,0x7806,0x6827,0x18c0,0x08e1,0x3882,0x28a3,
        0xcb7d,0xdb5c,0xeb3f,0xfb1e,0x8bf9,0x9bd8,0xabbb,0xbb9a,
        0x4a75,0x5a54,0x6a37,0x7a16,0x0af1,0x1ad0,0x2ab3,0x3a92,
        0xfd2e,0xed0f,0xdd6c,0xcd4d,0xbdaa,0xad8b,0x9de8,0x8dc9,
        0x7c26,0x6c07,0x5c64,0x4c45,0x3ca2,0x2c83,0x1ce0,0x0cc1,
        0xef1f,0xff3e,0xcf5d,0xdf7c,0xaf9b,0xbfba,0x8fd9,0x9ff8,
        0x6e17,0x7e36,0x4e55,0x5e74,0x2e93,0x3eb2,0x0ed1,0x1ef0
    };

    uint16_t crc16(const char *buf, int len) {
        int counter;
        uint16_t crc = 0;
        for (counter = 0; counter < len; counter++)
                crc = (crc<<8) ^ crc16tab[((crc>>8) ^ *buf++)&0x00FF];
        return crc;
    }

